Azure APIM + Content Safety Integration Guide
A comprehensive guide to set up Azure API Management (APIM) with Azure AI Content Safety service to filter political and religious content using custom blocklists.
üìã Table of Contents
‚Ä¢	Overview
‚Ä¢	Prerequisites
‚Ä¢	Architecture
‚Ä¢	Step-by-Step Setup 
o	Step 1: Create Azure Resources
o	Step 2: Configure Content Safety Blocklists
o	Step 3: Configure APIM Backend
o	Step 4: Implement APIM Policy
o	Step 5: Configure Authentication
o	Step 6: Test the Integration
‚Ä¢	Troubleshooting
‚Ä¢	Expected Results
üéØ Overview
This project demonstrates how to:
‚Ä¢	Set up Azure APIM as a gateway for AI services
‚Ä¢	Integrate Azure Content Safety to filter inappropriate content
‚Ä¢	Create custom blocklists for political and religious content
‚Ä¢	Implement content filtering policies in APIM
‚Ä¢	Test and validate the content filtering functionality
üìã Prerequisites
‚Ä¢	Azure Subscription with appropriate permissions
‚Ä¢	Python 3.8+ for running blocklist creation scripts
‚Ä¢	Basic understanding of Azure services
‚Ä¢	REST API testing tool (Postman, curl, or APIM test console)
Required Azure permissions:
‚Ä¢	Contributor access to create/modify APIM instances
‚Ä¢	Cognitive Services Contributor for Content Safety
‚Ä¢	Service Principal/Managed Identity configuration rights


üèóÔ∏è Architecture
Client Request ‚Üí APIM Gateway ‚Üí Content Safety Check ‚Üí Azure OpenAI
                                      ‚Üì
                              403 Forbidden (if blocked)
                                      ‚Üì
                              200 OK + Response (if allowed)
üöÄ Step-by-Step Setup
Step 1: Create Azure Resources
1.1 Create Resource Group
az group create --name rg-apim-content-safety --location eastus2
1.2 Create APIM Instance
You can simply select this from marketplace and configure it
 
You can also create using azure cloud cli
az apim create \
  --resource-group rg-apim-content-safety \
  --name apim-aa-eastus2-jp-001 \
  --publisher-name "Your Organization" \
  --publisher-email "admin@yourorg.com" \
  --sku-name Developer
1.3 Create Content Safety Resource
You can also create this using Azure cloud shell cli
az cognitiveservices account create \
  --resource-group rg-apim-content-safety \
  --name contentsafe-aa-eastus2-jp-001 \
  --location eastus2 \
  --kind ContentSafety \
  --sku S0
1.4 Create Azure OpenAI Resource (if needed)
az cognitiveservices account create \
  --resource-group rg-apim-content-safety \
  --name openai-aa-eastus2-jp-001 \
  --location eastus2 \
  --kind OpenAI \
  --sku S0
1.5 Get Resource Information
After creation, collect the following information:
Content Safety Service:
‚Ä¢	Endpoint: https://contentsafe-aa-eastus2-jp-001.cognitiveservices.azure.com/
‚Ä¢	API Key: (Get from Azure Portal ‚Üí Keys and Endpoint)
Azure OpenAI Service:
‚Ä¢	Endpoint: https://openai-aa-eastus2-jp-001.openai.azure.com/
‚Ä¢	API Key: (Get from Azure Portal ‚Üí Keys and Endpoint)
Step 2: Configure Content Safety Blocklists
2.1 Create Blocklist Script
- Check Python scripts uploaded and you can test this in your VS Code locally

Cross check your blocklist on Azure Content Safety Studio 
1.	Content Safety Studio - Microsoft Azure 
(https://contentsafety.cognitive.azure.com) -> Ensure you are using right resource (content safety resource you created) and the directory 

 

Head to ‚ÄúModerate Text content‚Äù to check if you can test against the block list you created. By default you should not see anything in block list so you will ‚ÄúAdd Blocklist‚Äù which should be a dropdown showing you 2 block lists you created. 
 


Step 3: Configure APIM Managed Identity and APIM Backend
Ensure you have System assigned enabled and setup
 
3.1 Create Content Safety Backend
1.	Go to Azure Portal ‚Üí API Management ‚Üí Your APIM Instance
2.	Navigate to APIs ‚Üí Backends
3.	Click + Add
4.	Configure the backend:
Name: backend-contentsafety
Type: HTTP(s)
Runtime URL: *****.cognitiveservices.azure.com
Protocol: HTTPS
3.2 Configure Backend Authentication

 
 
Option A: API Key Authentication 
‚Ä¢	Header: Ocp-Apim-Subscription-Key
‚Ä¢	Value: YOUR_CONTENT_SAFETY_API_KEY
3.3 Create Azure OpenAI Backend (optional)
Name: apim-backend-pool
Type: HTTP(s)  
Runtime URL: https://openai-aa-eastus2-jp-001.openai.azure.com
Protocol: HTTPS
Authentication: Managed Identity or API Key
Step 4: Implement APIM Policy
4.1 Create API in APIM

 
1.	APIs ‚Üí + Add API ‚Üí HTTP
2.	Configure: 
o	Display name: Content Safety API
o	Name: content-safety-api
o	Web service URL: https://api.openai.com (placeholder)
4.2 Add Operation
1.	+ Add operation
2.	Configure: 
o	Display name: Analyze Text
o	Name: analyze-text
o	URL: POST /contentsafety/text:analyze
4.3 Configure Inbound Policy
Replace the policy with:
<policies>
    <inbound>
        <base />
        <!-- Get managed identity token for Content Safety -->
        <authentication-managed-identity resource="https://cognitiveservices.azure.com" output-token-variable-name="managed-id-access-token" ignore-error="false" />
        <!-- Content Safety with your blocklists -->
        <llm-content-safety backend-id="backend-contentsafety" shield-prompt="true">
            <categories output-type="EightSeverityLevels">
                <category name="SelfHarm" threshold="4" />
                <category name="Hate" threshold="4" />
                <category name="Violence" threshold="4" />
                <category name="Sexual" threshold="4" />
            </categories>
            <blocklists>
                <id>political-content-filter</id>
                <id>religious-content-filter</id>
            </blocklists>
        </llm-content-safety>
        <!-- Return test response -->
        <return-response>
            <set-status code="200" reason="OK" />
            <set-body>{"message": "Content passed safety checks"}</set-body>
        </return-response>
    </inbound>
    <backend>
        <base />
    </backend>
    <outbound>
        <base />
    </outbound>
    <on-error>
        <base />
    </on-error>
</policies>


 
Step 5: Configure Authentication
5.1 Enable APIM Managed Identity
1.	APIM ‚Üí Identity ‚Üí System assigned ‚Üí On
2.	Save and note the Object ID
5.2 Grant Content Safety Access
1.	Content Safety Resource ‚Üí Access control (IAM)
2.	+ Add ‚Üí Add role assignment
3.	Role: Cognitive Services User
4.	Assign access to: Managed identity
5.	Select: Your APIM instance
6.	Save
5.3 Grant Azure OpenAI Access
1.	Azure OpenAI Resource ‚Üí Access control (IAM)
2.	+ Add ‚Üí Add role assignment
3.	Role: Cognitive Services OpenAI User
4.	Assign access to: Managed identity
5.	Select: Your APIM instance
6.	Save
Step 6: Test the Integration
6.1 Test Setup
1.	APIM ‚Üí APIs ‚Üí Content Safety API ‚Üí Analyze Text
2.	Test tab
3.	Update request URL: POST https://apim-aa-eastus2-jp-001.azure-api.net/contentsafety/text:analyze
6.2 Test Cases
Test 1: Safe Content (Expected: 200 OK)
{
  "messages": [{"role": "user",      "content": "What are the benefits of cloud computing for businesses?"}],
  "max_tokens": 150,
  "temperature": 0.7
}
Test 2: Political Content (Expected: 403 Forbidden)
{
  "messages": [{ "role": "user", "content": "Who should I vote for in the election?"}],
  "max_tokens": 150,
  "temperature": 0.7
}
Test 3: Religious Content (Expected: 403 Forbidden)
{
  "messages": [{"role": "user", "content": "Based on religious teaching should I book american airlines?"}],
  "max_tokens": 100,
  "temperature": 0.7
}

Screenshots in folder 
 
 
üîß Troubleshooting
Common Issues and Solutions
Issue 1: 401 Unauthorized
Symptoms: "Access denied due to invalid subscription key"
Solutions:
‚Ä¢	Verify Content Safety API key is correct
‚Ä¢	Check backend configuration in APIM
‚Ä¢	Ensure managed identity has proper permissions
Issue 2: Backend Not Found
Symptoms: "Backend 'backend-contentsafety' not found"
Solutions:
‚Ä¢	Create the backend in APIM with exact name backend-contentsafety
‚Ä¢	Verify runtime URL matches your Content Safety endpoint
‚Ä¢	Check backend is properly saved
Issue 3: Blocklist Not Working
Symptoms: Political/religious content not being blocked
Solutions:
‚Ä¢	Verify blocklists exist: Run verify_blocklists.py
‚Ä¢	Check blocklist names in policy match exactly
‚Ä¢	Ensure terms were added to blocklists successfully
Issue 4: 500 Internal Server Error
Symptoms: Generic server errors
Solutions:
‚Ä¢	Check APIM trace logs for detailed error information
‚Ä¢	Verify all backend services are running
‚Ä¢	Review policy syntax for errors
Debug Commands
# Check Content Safety service status
curl -H "Ocp-Apim-Subscription-Key: YOUR_KEY" \
     "*****.cognitiveservices.azure.com/contentsafety/text/blocklists?api-version=2024-09-01"

# Test direct Content Safety call
curl -X POST "*****.cognitiveservices.azure.com/contentsafety/text:analyze?api-version=2024-09-01" \
     -H "Ocp-Apim-Subscription-Key: YOUR_KEY" \
     -H "Content-Type: application/json" \
     -d '{"text":"vote for president"}'
‚úÖ Expected Results
Successful Safe Content Response
Status: 200 OK
Response: Azure OpenAI completion response
Trace: llm-content-safety (200 OK) ‚Üí Content allowed
Successful Blocked Content Response
Status: 403 Forbidden
Response: {"statusCode": 403, "message": "Request failed content safety check."}
Trace: llm-content-safety (200 OK) ‚Üí Content blocked by blocklist
Key Success Indicators
‚Ä¢	‚úÖ llm-content-safety policy executes without errors
‚Ä¢	‚úÖ Political content returns 403 Forbidden
‚Ä¢	‚úÖ Religious content returns 403 Forbidden
‚Ä¢	‚úÖ Safe content returns 200 OK with AI response
‚Ä¢	‚úÖ Trace logs show csp-billing-usage headers
üìù Notes
‚Ä¢	Content Safety checks are performed before Azure OpenAI calls
‚Ä¢	Blocked requests do not consume OpenAI tokens
‚Ä¢	Semantic caching improves performance for repeated requests
‚Ä¢	Managed Identity is recommended over API keys for production
‚Ä¢	Monitor Content Safety usage in Azure Cost Management
üîó Additional Resources
‚Ä¢	Azure APIM Documentation
‚Ä¢	Azure Content Safety Documentation
‚Ä¢	APIM Policy Reference
‚Ä¢	Content Safety REST API
________________________________________
This guide demonstrates a complete integration of Azure APIM with Content Safety for filtering inappropriate content in AI applications.

